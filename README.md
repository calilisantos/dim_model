# Boas vindas ao **dim_model!**

Para executar o projeto, observe as orienta√ß√µes descritas a seguir, e se tiver qualquer d√∫vida, sugest√£o, contribui√ß√£o, considere abrir uma issue ou entrar em contato. üöÄ

Aqui voc√™ vai encontrar os detalhes de como est√° estruturado e foi desenvolvido o projeto.

# <a id='topicos'>T√≥picos</a>
- [Desenvolvimento](#desenvolvimento)
  - [Objetivo](#objetivo)
  - [Estrutura do projeto](#estrutura)
  - [Tecnologias utilizadas](#tecnologias)
- [Orienta√ß√µes](#orientacoes)
  - [Executando o projeto](#execucao)
    - [1. Sem o docker](#sem-docker)
    - [2. Com o docker](#com-docker)
  - [Linter](#linter)
  - [Testes](#testes)
  - [Diagrama ER e Modelagem dos dados](#der)
- [Implementa√ß√µes](#implementacoes)
  - [Contextualizando](#contextualizando)
  - [Consumindo as tabelas](#consumindo)
- [Pr√≥ximos passos](#next)

# <a id='desenvolvimento'>[Desenvolvimento](#topicos)</a>

<strong><a id='objetivo'>[Objetivo](#topicos)</a></strong>

  O **objetivo** √© fazer a modelagem dimensional de um controle de cheques, atualmente em [**planilhas excel**](dim_model/sheets).
  
  Para isso, foi feita a [**Extra√ß√£o, Transforma√ß√£o e Carga (ETL)**](#tecnologias) e [**modelagem dos dados**](#der) tornando a disponibilidade e consumo dos dados escal√°vel e com maior seguran√ßa.

  ---

<strong><a id='estrutura'>[Estrutura do projeto](#topicos)</a></strong>

* **Na pasta [dim_model](dim_model) est√£o os diret√≥rios:**
  * **[configs](dim_model/configs)** com os arquivos de configura√ß√£o da execu√ß√£o do c√≥digo-fonte. Possui **_as regras de neg√≥cio_** da aplica√ß√£o;
  * **[sheets](dim_model/sheets)** com os arquivos de origem dos dados mascarados do controle de cheques atual.
* **E os arquivos:**
  * **[read.py](dim_model/read.py)** com a classe **Read**, que l√™ os dados das planilhas retornando um dataframe pandas para tratamento dos dados;
  * **[transform.py](dim_model/transform.py)** com a classe **Transform**, executora do tratamento dos dados brutos √† partir das regras de neg√≥cio definidas;
  * **[model.py](dim_model/model.py)** com a classe **Model** que cont√©m a modelagem nos dados tratados para cria√ß√£o das tabelas fato e dimens√µes;
  * **[write.py](dim_model/write.py)** com a classe **Write** que abstrai a escrita dos dados modelados para suas respectivas tabelas;
  * **[orchestrator.py](dim_model/orchestrator.py)** com a classe **Orchestrator** que orquestra a execu√ß√£o dos objetos das classes anteriores, simulando uma **pipeline de dados**.
  * **[main.py](dim_model/main.py)** com a classe **Main**, executora do c√≥digo-fonte da classe Orchestrator.
  * **[transform_data.ipynb](dim_model/transform_data.ipynb)** notebook jupyter com o c√≥digo-fonte original (n√£o utilizado no projeto atual).
* **Na pasta [images](images) est√£o os arquivos:**
  * **[EER.png](images/EER.png)** imagem com o schema **[da modelagem dos dados](#der)** final das tabelas criadas;
  * **[sheet_structure.png](images/sheet_structure.png)** imagem com sample das planilhas fonte de dados;
* **Na pasta [tests](tests) est√£o os arquivos com os testes dos respectivos arquivos do c√≥digo-fonte.**
* **E os arquivos:**
  * **[#.env](#.env)** com as vari√°veis de ambiente utilizadas na aplica√ß√£o para comunica√ß√£o com o banco `mysql`. 
    >IMPORTANTE:<br/>Tire a hashtag do nome do arquivo para execu√ß√£o do projeto.
  * **[docker-compose.yml](docker-compose.yml)** arquivo que possibilita a execu√ß√£o da aplica√ß√£o, orquestrando as imagens docker do `mysql` e `python`;
  * **[Dockerfile.MySQL](Dockerfile.MySQL)** container docker do `mysql` para cria√ß√£o do servidor deste banco de dados, com as especifica√ß√µes necess√°rias para a aplica√ß√£o;
  * **[Dockerfile.Python](Dockerfile.Python)** container docker do `python` com as especifica√ß√µes necess√°rias para a aplica√ß√£o;
  * **[mysql_local.sh](mysql_local.sh)** c√≥digo shell criado como op√ß√£o **[para execu√ß√£o do c√≥digo sem um servidor `mysql` local](#execucao)**
  * **[requirements.txt](requirements.txt)** arquivo com as depend√™ncias necess√°rias e utilizadas para execu√ß√£o do projeto;
  * **[tox.ini](tox.ini)** arquivo com a configura√ß√£o de uso da [an√°lise est√°tica do c√≥digo](#linter).

<strong><a id='tecnologias'>[Tecnologias utilizadas](#topicos)</a></strong>

  O projeto foi desenvolvido em Python para constru√ß√£o do script de ETL e modelagem de dados.

  Para o processamento dos dados, essas foram as bibliotecas utilizadas:

* **[Pandas](https://pandas.pydata.org/):**
  * Ferramenta open source focada na facilidade para manipula√ß√£o e an√°lise de dados, totalmente integrada com a linguagem python;
* **[SQLAlchemy](https://www.sqlalchemy.org/):**
  * ORM python, utilizada para relacionar um c√≥digo python com os dados que ele se relaciona principalmente de um banco de dados relacional (SQL).
* **[SQLAlchemy-utils](https://sqlalchemy-utils.readthedocs.io/en/latest/):**
  * Built-in do `SQLAlchemy` que abstrai fun√ß√µes do seu mapeamento da fonte de dados utilizadas.

>No arquivo de depend√™ncias, **[requirements.txt](requirements.txt)**, √© listada outras depend√™ncias acess√≥rias √† essas bibliotecas e tamb√©m utilizadas para **[an√°lise do c√≥digo](#linter)** e **[testes da aplica√ß√£o](#testes)**.
    
# <a id='orientacoes'>[Orienta√ß√µes](#topicos)</a>

<strong><a id='execucao'>[Executando o projeto](#topicos)</a></strong>

A aplica√ß√£o foi pensada para ser testada com o `Docker`, visando torn√°-la o mais agn√≥stica poss√≠vel.

√â poss√≠vel sua execu√ß√£o sem a ferramenta, com sugest√µes para os dois cen√°rios abaixo:

>**IMPORTANTE**<br/>Independente da escolha, ap√≥s clonar o projeto, entre com seu terminal na pasta criada:<br/>`cd dim_model`<br/>**Todas orienta√ß√µes abaixo, tem essa pasta como refer√™ncia.**


<!-- <h3><strong><a id='sem-docker'>1. Execu√ß√£o sem o docker:</a></strong></h3> -->

### <strong><a id='sem-docker'>[1. Execu√ß√£o sem o docker:](#topicos)</a></strong>

Nesse cen√°rio, √© necess√°rio que sua m√°quina possua instalado: i. um servidor `mysql`; ii. e o `python`. Sobre essas ferramentas:

#### **i. MySQL:**

  >Atualize o arquivo [.env](.env) com as configura√ß√µes do seu servidor local.

  ```docker
  DB_USER=root
  DB_NAME=Checks
  DB_PASSWORD=123456
  DB_HOST=mysql_db
  ```

#### **ii. Python:** 
  
  O projeto foi constru√≠do com o python na vers√£o 3.8, por√©m **n√£o se espera indisponibilidades com sua execu√ß√£o √† partir da vers√£o 3.4.** 

  **Qualquer incompatibilidade com a vers√£o da sua m√°quina por favor informe.**

  Ainda, √© recomendada a instala√ß√£o pr√©via do gerenciador de pacotes `pip` para os passos a seguir:

  >**(Recomendado)** **Utilizar um ambiente virtual** com os seguintes comandos (nome `model_venv` j√° considerado na ferramenta de [lint](#lint)):
  ```shell
  # cria o ambiente com o nome model_venv:
  python3 -m venv model_venv 
  # ativa o ambiente em terminais Linux e Mac:
  source model_venv/bin/activate
  # ativa o ambiente em terminal Windows (cmd):
  model_venv\bin\activate
  ```
  >1.**Instalar depend√™ncias do projeto:**
  ```ps1
  pip install -r requirements.txt
  ```
  >2.**Setar PYTHONPATH:**
  ```shell
  export PYTHONPATH=./
  ```
  >3.**Executar projeto (na pasta criada com o clone):**
  ```bash
  python3  dim_model/main.py
  ```
  >4.**Executar projeto instanciando a classe Main (na pasta criada com o clone):**
  ```python
  from dim_model.main import Main

  Main().run_pipeline()
  ```
  >5.**Executando testes (na pasta criada com o clone):**
  ```ps1
  pytest -v
  pytest --cov=tests/
  ```

### <strong><a id='com-docker'>[2. Execu√ß√£o com o docker:](#topicos)</a></strong>

>**IMPORTANTE**<br/>Nesse cen√°rio recomenda-se utilizar as vers√µes a seguir das ferramentas docker:<br/>`docker:25.0.3`  `docker-compose:1.29.2` <br/>**Verifique suas vers√µes com os comandos:** <br/>`docker version` e `docker-compose -v`

### 2.1. Usando imagem docker do MySQL (para Linux ou Mac):
Caso n√£o possua ou opte por n√£o usar um servidor mysql, execute o seguinte comando:
```bash
# na raiz do projeto, d√™ permiss√£o para execu√ß√£o do script mysql_local.sh:
chmod 777 ./mysql_local.sh
# execute o arquivo:
./mysql_local.sh
```
>**IMPORTANTE**<br/>Esse script modifica o valor do host no arquivo .env. Caso use as outras formas de execu√ß√£o do projeto depois, restaure o valor original do arquivo.

Caso tenha problema na execu√ß√£o do script, veja a situa√ß√£o do container que ele cria:
```bash
# verifique se o container est√° em execu√ß√£o:
docker ps -la
# caso n√£o esteja em execu√ß√£o, veja logs do container
docker logs mysql_db
# para parar o container caso necess√°rio:
docker stop mysql_db
# ap√≥s par√°-lo apague-o:
docker rm mysql_db
```

Com o container local em execu√ß√£o, siga √° partir do passo 3 da execu√ß√£o do c√≥digo com `python` [dessa se√ß√£o](#topicos)

### 2.2. Usando docker-compose para orquestrar imagens:
Com o docker-compose n√£o √© necess√°rio ter o python nem o mysql instalados localmente. Nessa op√ß√£o, a execu√ß√£o do c√≥digo ser√° feita automaticamente tamb√©m.

Passos para sua inicializa√ß√£o:
```bash
# na raiz do projeto, inicie os containers:
docker-compose up -d
# confirme que est√£o de p√©:
docker-compose ps
# caso tenha erro, ver logs do problema do container:
docker-compose logs python_env # exemplo com container python
# vendo logs de todos os containers:
docker-compose logs
# com a corre√ß√£o do erro, derrube os containers:
docker-compose down
# derrubando os containers for√ßando a limpeza dos seus volumes:
docker-compose down -v
# reiniciando containers for√ßando recria√ß√£o de um deles:
docker-compose up -d --force-recreate python_env
```

Com o funcionamento dos containers, √© poss√≠vel executar os arquivos do projeto dessa forma:
```bash
# visualizando execu√ß√£o do projeto:
docker-compose logs python_env
# executando arquivo do container:
docker exec <container_name_or_id> python /caminho/para/seu/arquivo.py
# exemplo de execu√ß√£o dos testes do c√≥digo:
docker exec python_env pytest -v
# executando arquivos dentro do container:
docker exec -it <container_name> bash
# ex para o mysql (na sequ√™ncia √© solicitada a senha):
docker exec -it mysql_db mysql -u root -p
# com a .env sugerida, a senha √©: 123456
```

<strong><a id='linter'>[Linter](#topicos)</a></strong>

Foi utilizado o [**flake8**](https://flake8.pycqa.org/en/latest/) para fazer a an√°lise est√°tica do c√≥digo visando garantir as boas pr√°ticas e legibilidade do c√≥digo.

Com a execu√ß√£o utilizando o `docker-compose` √© mostrado o resultado da an√°lise do c√≥digo-fonte.

>Considere instalar as configura√ß√µes do flake8 no seu editor de texto para contribui√ß√µes no projeto.

Para executar o `flake8`, no seu terminal Mac ou Linux:
```bash
# na raiz do projeto:
flake8
# analisando um diret√≥rio em espec√≠fico:
flake8 dim_model/
# analisando um arquivo em espec√≠fico:
flake8 dim_model/model.py
```

<strong><a id='testes'>[Testes](#topicos)</a></strong>

Ser√£o utilizadas as bibliotecas _xUnit_ e _FluentAssertions_ para desenvolvimento dos testes da aplica√ß√£o. 

  A cobertura m√≠nima do c√≥digo definida foi de 30%, melhor descrita na se√ß√£o de implementa√ß√µes.

  **_Para executar os testes localmente, digite no terminal o comando `dotnet test`._**

Foi utilizado o **[pytest](https://docs.pytest.org/en/8.0.x/)** e **[unittest](https://docs.python.org/3/library/unittest.html)** para constru√ß√£o dos testes (por enquanto somente unit√°rios) da aplica√ß√£o.

Mais detalhes na documenta√ß√£o desses testes.

<strong><a id='der'>[Diagrama ER e Modelagem dos dados](#topicos)</a></strong>

Buscou-se implementar uma modelagem **_star-schema_** para otimizar a leitura dos dados originais. 

As planilhas de origem tem as seguintes colunas:
  ![sheet_structure](images/sheet_structure.png)
Elas comp√µem as principais informa√ß√µes para controle de movimento de cheques recebidos pela empresa. 

A constru√ß√£o das tabelas atrav√©s do SQLAlchemy, seguiu o seguinte *DER*:

  ![DER](images/EER.png)

  ---

## Formato das entidades
O de-para dos dados originais para esses √© descrito abaixo
### Tabela bank_dim:
|Coluna|Tipo|Descri√ß√£o|Origem|
|-|-|-|-|
|bank_id|INT|ID √∫nico do banco|Coluna BANCO|
|bank_name|VARCHAR|nome do banco|Coluna BANCO|
### Tabela check_dim:
|Coluna|Tipo|Descri√ß√£o|Origem|
|-|-|-|-|
|check_id|INT|ID √∫nico do cheque|Colunas BANCO, N¬∫ CHEQUE, VALOR (R$), VENCIMENTO|
|check_number|INT|N√∫mero do cheque|Coluna N¬∫ CHEQUE|
|check_amount|DOUBLE|Valor do cheque|Coluna VALOR (R$)|
|maturity_date|DATETIME|Data de vencimento do cheque|Coluna VENCIMENTO|
### Tabela dest_dim:
|Coluna|Tipo|Descri√ß√£o|Origem|
|-|-|-|-|
|destination_id|INT|ID √∫nico do destino do cheque|Coluna COD|
|destination_type|VARCHAR|Nome do destino|Coluna COD|
### Tabela name_dim:
|Coluna|Tipo|Descri√ß√£o|Origem|
|-|-|-|-|
|name_id|INT|ID √∫nico do nome do cliente|Colunas CLIENTE|
|name|VARCHAR|Nome do cliente|Colunas CLIENTE e OBSERVA√á√ÉO|
|is_client|BOOLEAN|Boleano que compara as colunas CLIENTE e OBSERVA√á√ÉO|Colunas CLIENTE e OBSERVA√á√ÉO|
|client_name|VARCHAR|Nome do cliente √† partir da coluna is_client|Colunas CLIENTE e OBSERVA√á√ÉO e is_client|
### Tabela check_fact:
|Coluna|Tipo|Descri√ß√£o|Origem|
|-|-|-|-|
|id|INT|ID √∫nico do fato|Todas as colunas|
|bank_id|INT|ID √∫nico do banco|Coluna BANCO|
|check_id|INT|ID √∫nico do cheque|Colunas BANCO, N¬∫ CHEQUE, VALOR (R$), VENCIMENTO|
|destination_id|INT|ID √∫nico do destino do cheque|Coluna COD|
|name_id|INT|ID √∫nico do nome do cliente|Colunas CLIENTE|
|is_in_cash|BOOLEAN|Booleano se o cheque est√° no caixa|Colunas SA√çDA, COD e DESTINO|
|description|VARCHAR|Descri√ß√£o do cheque|Coluna DESTINO|
|registration_date|DATETIME|data estimada do fato|Colunas VENCIMENTO e SA√çDA|

### Mande seu feedback sobre o projeto!

Se estiver a vontade, clone o reposit√≥rio e, seja com ou sem o Docker, execute, veja o deploy e me ajude a melhorar este projeto! Seu feedback ser√° super bem vindo!

# <a id='implementacoes'>[Implementa√ß√µes](#topicos)</a>

<strong><a id='contextualizando'>[Contextualizando](#topicos)</a></strong>

  Com a utiliza√ß√£o do controle de cheques ao longo do tempo, observou-se pontos de aten√ß√£o quanto √† manuten√ß√£o, acur√°cia e manejo do seu uso.

  A cada m√™s novas abas eram manejadas manualmente. Sem valida√ß√µes dos campos, erros de digita√ß√£o eram comuns. Tamb√©m a seguran√ßa, backup e controle de uso eram oportunidades de melhoria.
  
  A op√ß√£o de utilizar um banco de dados permite maior dilig√™ncia, acur√°cia e escalabilidade do controle. 
  
  O projeto permite o aproveitamento do hist√≥rico e convers√£o dos dados atuais na planilha, possibilitando a constru√ß√£o de uma interface para manejo dos dados, al√©m de direcionar os pontos de observa√ß√£o avaliados.

  O uso da modelagem dimensional vem da expertise como engenheiro de dados. O python, docker, mysql facilitam a cria√ß√£o do processo e integra√ß√£o com outras futuras solu√ß√µes de engenharia de software que possam ser utilizadas.
  
<strong><a id='consumindo'>[Consumindo as tabelas](#topicos)</a></strong>

Alguns scripts para testar o resultado do projeto no servidor mysql local ou do container:

```sql
<!-- utilizando database criado -->
USE Checks;
<!-- mostrando tabelas criadas -->
SHOW TABLES;
<!-- consultando uma tabela dimens√£o -->
SELECT * FROM bank_dim;
<!-- consultando tabelas como planilha atual -->
SELECT
    id,
    N.name AS CHECK_OWNER,
    N.client_name AS CLIENT_NAME,
    B.bank_name AS BANK_NAME,
    CK.check_number,
    CK.check_amount,
    CK.maturity_date,
    D.destination_type AS DESTINATION_TYPE,
    `description`,
    registration_date,
    is_in_cash
FROM check_fact AS C
JOIN name_dim AS N
ON C.name_id = N.name_id
JOIN bank_dim AS B
ON C.bank_id = B.bank_id
JOIN check_dim AS CK
ON C.check_id = CK.check_id
JOIN dest_dim AS D
ON C.destination_id = D.destination_id
WHERE
    DESTINATION_TYPE = "CAIXA"
    AND is_in_cash = TRUE
```
  
# <a id='next'>[Pr√≥ximos passos](#topicos)</a>

  As features mapeadas s√£o:

  * **Ampliar cen√°rios de testes** garantindo o design da aplica√ß√£o;

  * **Construir uma esteira de CI/CD** para garantir a governan√ßa das implementa√ß√µes do projeto;

  * **Orquestrar o ambiente com Kubernetes**, adicionando uma op√ß√£o de disponibilidade da execu√ß√£o do projeto.

  * **Gerenciar os containers com helm**, adicionando uma op√ß√£o din√¢mica de disponibilidade da execu√ß√£o do projeto.

---
